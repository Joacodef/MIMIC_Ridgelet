{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baea4554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from monai.transforms import LoadImaged\n",
    "\n",
    "# Add the project source to the Python path\n",
    "# This allows us to import modules from the 'src' directory\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.data.transforms import RidgeletTransformd\n",
    "\n",
    "# Set notebook style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3aff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from a .env file at the project root\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "IMAGE_ROOT_DIR = os.getenv(\"MIMIC_CXR_P_FOLDERS_PATH\")\n",
    "PROJECT_DATA_FOLDER_PATH = os.getenv(\"PROJECT_DATA_FOLDER_PATH\")\n",
    "\n",
    "if not all([IMAGE_ROOT_DIR, PROJECT_DATA_FOLDER_PATH]):\n",
    "    raise ValueError(\n",
    "        \"Please ensure MIMIC_CXR_P_FOLDERS_PATH, PROJECT_DATA_FOLDER_PATH are set in your .env file.\"\n",
    "    )\n",
    "\n",
    "print(f\"Image root directory loaded.\")\n",
    "print(f\"Metadata CSV path loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd556e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Define paths and load the validation split ---\n",
    "split_folder_name = \"split_2000\"\n",
    "val_csv_path = os.path.join(PROJECT_DATA_FOLDER_PATH, \"splits\", split_folder_name, \"validation.csv\")\n",
    "df_val = pd.read_csv(val_csv_path)\n",
    "\n",
    "# --- 2. Construct the full path to the metadata CSV file ---\n",
    "metadata_dir = os.getenv(\"MIMIC_CXR_METADATA_PATH\")\n",
    "metadata_filename = \"mimic-cxr-2.0.0-metadata.csv\"\n",
    "full_metadata_path = os.path.join(metadata_dir, metadata_filename)\n",
    "\n",
    "# --- 3. Load the metadata and merge with the validation split ---\n",
    "print(f\"Loading metadata from: {full_metadata_path}\")\n",
    "if not os.path.exists(full_metadata_path):\n",
    "    raise FileNotFoundError(f\"Error: The metadata file was not found at the expected path: {full_metadata_path}\")\n",
    "\n",
    "df_meta = pd.read_csv(full_metadata_path)\n",
    "df_merged = pd.merge(df_val, df_meta[['dicom_id', 'subject_id', 'study_id']], on='dicom_id', how='left')\n",
    "\n",
    "# --- 4. Select a sample that specifically has a fracture ---\n",
    "# Filter the DataFrame for records where 'fracture_present' is 1.\n",
    "df_fractures = df_merged[df_merged['fracture'] == 1]\n",
    "\n",
    "# Check if any fracture cases exist in the validation set.\n",
    "if df_fractures.empty:\n",
    "    raise ValueError(\"No fracture cases were found in the validation split. Cannot select a sample.\")\n",
    "\n",
    "# Select the first record from the filtered list of fractures.\n",
    "sample_record = df_fractures.iloc[0].to_dict()\n",
    "\n",
    "subject_id = str(int(sample_record['subject_id_x']))\n",
    "study_id = str(int(sample_record['study_id_x']))\n",
    "dicom_id = str(sample_record['dicom_id'])\n",
    "\n",
    "# Construct the relative path based on the standard MIMIC-CXR-JPG directory structure\n",
    "image_relative_path = os.path.join(\n",
    "    f\"p{subject_id[:2]}\",\n",
    "    f\"p{subject_id}\",\n",
    "    f\"s{study_id}\",\n",
    "    f\"{dicom_id}.jpg\"\n",
    ")\n",
    "full_image_path = os.path.join(IMAGE_ROOT_DIR, image_relative_path)\n",
    "\n",
    "# --- 5. Prepare the dictionary for MONAI ---\n",
    "sample_dict = {\"image\": full_image_path}\n",
    "\n",
    "print(f\"\\nSuccessfully located image with a fracture for visualization:\\n{full_image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00177f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms import Compose, LoadImaged, Resized, EnsureChannelFirstd\n",
    "import torch\n",
    "\n",
    "# Define a square size for the transform.\n",
    "# The FRT is most efficient with sizes that are powers of 2.\n",
    "SQUARE_SIZE = 512\n",
    "\n",
    "# 1. Create a corrected, robust processing pipeline.\n",
    "preprocess_pipeline = Compose([\n",
    "    # Loads the grayscale JPG image.\n",
    "    LoadImaged(keys=[\"image\"]),\n",
    "    # Safely ensures the image has a channel dimension, e.g., shape becomes [1, H, W].\n",
    "    # This is the standard way to prepare images and prevents the corruption error.\n",
    "    EnsureChannelFirstd(keys=[\"image\"]),\n",
    "    # Resize the image to a square.\n",
    "    Resized(keys=[\"image\"], spatial_size=(SQUARE_SIZE, SQUARE_SIZE))\n",
    "])\n",
    "\n",
    "# Apply the preprocessing steps\n",
    "loaded_and_resized_dict = preprocess_pipeline(sample_dict)\n",
    "\n",
    "# 2. Create an instance of the Ridgelet transform\n",
    "ridgelet_transformer = RidgeletTransformd(keys=[\"image\"], threshold_ratio=0.2)\n",
    "\n",
    "# 3. Apply the transform to the now-square, single-channel image data\n",
    "transformed_dict = ridgelet_transformer(loaded_and_resized_dict)\n",
    "\n",
    "# The transformed_dict now contains the reconstructed image\n",
    "# This will now be the correctly preprocessed X-ray image.\n",
    "original_image_tensor = loaded_and_resized_dict['image']\n",
    "transformed_image_tensor = transformed_dict['image']\n",
    "\n",
    "print(\"Original (resized) image shape:\", original_image_tensor.shape)\n",
    "print(\"Transformed image shape:\", transformed_image_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065dadc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Squeeze the channel dimension (C, H, W) -> (H, W) for grayscale plotting\n",
    "original_image_np = original_image_tensor.squeeze().numpy()\n",
    "transformed_image_np = transformed_image_tensor.squeeze().numpy()\n",
    "\n",
    "# Create a figure to display the images\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Plot Original Image - Add .T to transpose the array\n",
    "axes[0].imshow(original_image_np.T, cmap='gray')\n",
    "axes[0].set_title('Original Image', fontsize=16)\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Plot Reconstructed Image after Ridgelet Transform - Add .T here as well\n",
    "axes[1].imshow(transformed_image_np.T, cmap='gray')\n",
    "axes[1].set_title('Reconstructed Image (after Ridgelet)', fontsize=16)\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Magister",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
